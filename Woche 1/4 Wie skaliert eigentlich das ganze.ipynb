{"cells":[{"cell_type":"code","execution_count":null,"source":["# [Nur Colab] Diese Zellen müssen nur auf *Google Colab* ausgeführt werden und installieren Packete und Daten\n","!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n","!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Wie skaliert eigentlich das ganze?"],"metadata":{}},{"cell_type":"markdown","source":["## Machine Learning Daten skalieren\n","\n","Nun, da wir in der Lage sind, unsere Rohdaten zu laden und analysieren, können wir zum nächsten großen Schritt der Datenvorverarbeitung übergehen, dem Skalieren von Daten. Viele Machine-Learning Algorithmen erwarten skalierte Eingangsdaten. In diesem Kapitel werden wir lernen, wie Daten normalisiert und standardisiert werden können und wie wir entscheiden können, welches Verfahren das richtige ist. Dies ist vor allem für künstliche Neuronale Netze sowie Deep Learning wichtig.\n","\n","### Daten normalisieren\n","\n","Der Begriff Normalisieren sollte bereits aus der Mathematik bekannt sein. Dabei werden die Werte so angepasst, dass sie sich auf einer Skala zwischen 0 und 1 bewegen. Dazu brauchen wir den maximalen und den minimalen Wert jedes Attributs die wir durch einfaches Iterieren über die Werte finden können.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.1:</b> Schreiben Sie eine Funktion <code>dataset_minmax()</code>, die das Minimum und Maximum jedes Attributs findet.\n","<ul>\n","    <li> Hinweis: Die Funktion hat den Datensatz als Eingangsvariable und gibt eine Liste an Tupeln (Min, Max) für jede Spalte zurück.\n","\n","</ul>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# DO NOT change this cell\n","from pandas import read_csv\n","import pandas as pd\n","\n","filename = 'data/pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","data = read_csv(filename, names=names)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["# Find the min and max values for each column\n","def dataset_minmax(dataset: pd.DataFrame):\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","    return minmax\n","\n","# small test dataset\n","dataset = pd.DataFrame({'First' : [50, 30], 'Second' : [20, 90]})\n","print(dataset)\n","\n","# Calculate min and max for each column\n","minmax = dataset_minmax(dataset)\n","print(minmax)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Jetzt sind wir in der Lage, das Minimum und das Maximum jeder Spalte zu finden. Mit Hilfe dieser Werte und der folgenden Formel können wir dann unsere Werte normalisieren. \n","\n","$$scaled\\, value = \\frac{value - min}{max-min}$$\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.2:</b> Implementieren Sie diese Formel in der Funktion <code>normalize_dataset()</code>.\n","<ul>\n","    <li> Hinweis: Die Funktion hat den Datensatz und die Min-Max Werte als Eingangsvariablen und gibt den normalisierten Datensatz zurück.\n","\n","</ul>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["def normalize_dataset(dataset: pd.DataFrame, minmax: list):\n","    \n","    return_dataset = dataset.copy(deep=True)\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","            \n","    return return_dataset"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Wenn wir nun die gerade implementierten Funktionen kombinieren, können wir unseren Datensatz problemlos normalisieren. "],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["# Again a small test dataset\n","dataset =  pd.DataFrame({'First' : [50, 30], 'Second' : [20, 90], 'Third' : [30, 40]})\n","print(dataset)\n","\n","# Calculate min and max for each column\n","minmax = dataset_minmax(dataset)\n","print(minmax)\n","\n","# Normalize columns\n","dataset = normalize_dataset(dataset, minmax)\n","print(dataset)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Jetzt müssen wir nur noch alles zusammensetzten.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.3:</b> Implementieren Sie die Funktion <code>load_normalized_csv()</code>, die eine CSV Datei lädt und die Daten anschließend normalisiert. Gehen Sie davon aus, dass keine Header-Informationen vorhanden sind.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["def load_normalized_csv(filename: str):\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","\n","## Test:\n","filename = 'data/pima-indians-diabetes.csv'\n","\n","dataset = load_normalized_csv(filename)\n","\n","print(dataset.head())"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Standardize data\n","\n","Beim Standardisieren zentriert man seine Verteilung um 0 und setzt die Standardabweichung auf 1. Dadurch ergibt sich eine Gaußsche Normalverteilung, auch bekannt als Glockenkurve.\n","\n","Um standardisieren zu können, benötigen wir den Mittelwert und die Standardabweichung jeder Spalte unseres Datensets. Daher werden wir nun zunächst eine Funktion schreiben, die den Mittelwert jeder Spalte mit Hilfe der folgenden Formel berechnet:\n","\n","$$\\bar{x} = \\frac{\\sum_{n=0}^{N-1} x_n}{N}$$\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.4:</b> Schreiben Sie die Funktion <code>column_means()</code>, die den Mittelwert für jede Spalte im Datensatz zurückgibt.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["def column_means(dataset: pd.DataFrame):\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","    \n","    return means"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Wie wahrscheinlich bereits aus der Wahrscheinlichkeitstheorie bekannt, beschreibt die empirische Standardabweichung die durchschnittliche Streuung der Werte um den Mittelwert. Die nachfolgende Formel soll dabei helfen, eine Funktion zu schreiben, die die Standardabweichung berechnet.\n","\n","\n","$$ s = \\sqrt{\\frac{\\sum\\nolimits_{n=0}^{N-1}(x_n - \\bar{x})^2}{N}}$$\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.5:</b> Schreiben Sie eine Funktion <code>column_stdevs()</code>, die für jede Spalte die Standardabweichung mit der gegebenen Formel berechnet und in einer Liste zurückgibt.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["from math import sqrt\n","\n","def column_stdevs(dataset: pd.DataFrame, means: list):\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","        \n","    return stds"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Jetzt können wir unsere Mittelwert und Standardabweichung Funktionen mit einem kleinen Beispiel testen."],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["dataset = pd.DataFrame({'First' : [50, 30], 'Second' : [20, 90], 'Third' : [30, 50]})\n","print(dataset)\n","      \n","means = column_means(dataset)\n","print(means)\n","      \n","stdevs = column_stdevs(dataset, means)\n","print(stdevs)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Wir haben nun alle Tools, um unsere Daten standardisieren zu können."],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.6:</b> Implementieren Sie die Funktion <code>standardize_dataset()</code>, die die Werte im Datensatz standardisiert.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["def standardize_dataset(dataset: pd.DataFrame, means: list, stdevs: list):\n","    return_dataset = dataset.copy(deep=True)\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","    \n","    return return_dataset"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Jetzt ist es an der Zeit, alles zusammen zu setzten und die Standardisierungsfunktion zu testen.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.7:</b> Führen Sie alle benötigten Funktionen aus und geben Sie die Daten in einem Histogramm aus.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","\n","dataset = pd.DataFrame({'First' : [50, 10, 30], 'Second' : [20, 25, 90], 'Third' : [30, 40, 50]})\n","print(dataset)\n","\n","### STUDENT CODE HERE\n","\n","### STUDENT CODE until HERE\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Lass uns nun eine Funktion schreiben, die eine CSV Datei einließt und standardisiert.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.8:</b> Vervollständigen Sie die <code>load_standardized_csv()</code> Funktion, die eine Datei einliest und den standardisierten Datensatz zurückgibt.\n","</div>\n","\n"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["def load_standardized_csv(filename: str):\n","    \n","    ### STUDENT CODE HERE\n","\n","    ### STUDENT CODE until HERE\n","    return standardized_dataset\n","\n","## Test:\n","filename = 'data/pima-indians-diabetes.csv'\n","\n","dataset = load_standardized_csv(filename)\n","\n","print(dataset.head())"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Wann normalisieren und wann standardisieren?\n","\n","Neben den beiden vorgestellten Methoden gibt es viele weitere Arten der Datentransformation. \n","Allgemein zielen diese Transformation immer darauf ab, Strukturen der Daten bestmöglich für den Lernalgorithmus offen zu legen. \n","Die passende Transformationsmethode ist vom Anwendungsfall abhängig, sodass es im Allgemeinen nicht möglich ist, eine bestimmte Transformationsmethode einem bestimmten maschinellen Lernalgorithmus zuzuordnen.\n","Manchmal ist allerdings nicht offensichtlich, welcher Transformationstyp der beste ist. In solch einem Fall muss man ausprobieren, welcher Algorithmus der passendste ist („Trial and Error“)."],"metadata":{}},{"cell_type":"markdown","source":["## Daten für Machine-Learning vorbereiten\n","\n","Dies ist das letzte Kapitel zur Datenvorverarbeitung. Wie wir im vorangegangenen Kapitel gelernt haben, ist es sinnvoll, seine Daten zu verarbeiten und somit ihre besondere Struktur offenlegen. Dazu haben wir ein einfaches Python Programm geschrieben. Nun gehen wir noch einen Schritt weiter, in dem wir das Paket _scikit-learn_ verwenden. Nach dieser Aufgabe werden wir in der Lage sein, Daten zu normalisieren, standardisieren und binarisieren. \n","\n","Die scikit-learn Library enthält zwei verschiedene Standardwege, um Daten zu tansformieren."],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 1.4.9:</b> Recherchiere und beschreibe die Unterschiede.\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["### Daten Normalisieren\n","\n","Beim Normalisieren eines Datensatzes wird der größte Wert 1. Das ist hilfreich bei Datensätzen, die viele Nullen und unterschiedliche Skalen aufweisen. \n","\n","Mit Hilfe von scikit-learn können Daten mit der `MinMaxScaler` Klasse normalisiert werden."],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.10:</b> Min-Max-Normalisieren Sie die Daten aus dem Diabetes-Beispiel mit scikit-learn, indem Sie den <code>MinMaxScaler</code> verwenden, und speichern Sie sie in der Variable <code>dataframe_normalized</code>.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["# Rescale data (between 0 and 1)\n","from pandas import read_csv\n","from sklearn.preprocessing import MinMaxScaler\n","\n","filename = 'data/pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","\n","### STUDENT CODE HERE\n","\n","### STUDENT CODE until HERE\n","\n","dataframe_normalized.head()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Daten Standardisieren\n","\n","Eine weitere Möglichkeit ist die Standardisierung Ihrer Daten, die auch als z-Transformation bezeichnet wird. Das Ergebnis einer Standardisierung ist eine Verteilung mit einem Mittelwert von Null und einer Standardabweichung von 1.\n","\n","Sie können Daten standardisieren, indem Sie die Klasse `StandardScaler` in scikit-learn verwenden.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.11:</b> Standardisieren Sie die Daten des Diabetes-Beispiel mit dem <code>StandardScaler</code> und speichern Sie diese in der Variablen <code>dataframe_standardized</code>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["from pandas import read_csv\n","from sklearn.preprocessing import StandardScaler\n","\n","filename = 'data/pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","\n","### STUDENT CODE HERE\n","\n","### STUDENT CODE until HERE\n","dataframe_standardized.head()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Daten Binarisieren\n","Eine neue Methode der Datenvorverarbeitung ist die Binarisierung (Engl.: binarization). Hierbei wird ein Schwellenwert festgelegt. Alle Werte über der Schwelle werden zu eins, alle darunter zu null.\n","In scikit-learn kann dies mit Hilfe der Klasse `Binarizer` erreicht werden."],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.12:</b> \n","    Binarisieren Sie das Diabetes-Beispiel mit einem Schwellenwert von 0,0 und speichern Sie die binarisierten Daten in der Variablen <code>dataframe_binarized</code>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["from sklearn.preprocessing import Binarizer\n","from pandas import read_csv\n","\n","filename = 'data/pima-indians-diabetes.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","\n","### STUDENT CODE HERE\n","\n","### STUDENT CODE until HERE\n","dataframe_binarized.head()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Zusammenfassung\n","\n","In diesem Abschnitt haben wir gelernt, wie man Daten richtig einließt, versteht und vorverarbeitet. Dies ist von hoher Relevanz für die Anwendung von Daten auf Machine-Learning Algorithmen, da die Performanz solcher Algorithmen maßgeblich von der Qualität der verwendeten Daten abhängt.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 1.4.13:</b> \n","    <ul>\n","        <li>Fassen Sie in drei bis fünf Sätzen zusammen, welche Methoden Sie heute gelernt haben\n","        <li>Treffen Sie zwei Aussagen über den Datensatz, z. B. je mehr Kinder eine Person hat, desto älter ist die Person im Durchschnitt.\n","        <li>Sie können auch einige Plots oder Ausgaben verwenden, wenn Sie dies wünschen.\n","    </ul>\n","</div>\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}
